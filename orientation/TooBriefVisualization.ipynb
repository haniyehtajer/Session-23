{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Introduction to Visualization:\n",
    "Density Estimation and Data Exploration\n",
    "========\n",
    "\n",
    "##### Version 0.3\n",
    "\n",
    "***\n",
    "By AA Miller (Northwestern/CIERA)  \n",
    "08 May 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "**Notebook summary and goals**\n",
    "\n",
    "In this notebook you will learn about kernel density estimation (KDE) as an alternative to histograms, while building intution for how KDE works. There is also an introduction to [`seaborn`](https://seaborn.pydata.org/), a python package that is particularly well suited to exploring large dimension data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 1) Density Estimation\n",
    "\n",
    "We are in an era where data and large statistical samples are abundant, starting from 2MASS and SDSS to the Rubin Observatory. However, with this data explosion, we face the challenge of not knowing the underlying probability density function (PDF) of the observed random variables.\n",
    "\n",
    "Hence - density estimation: an attempt to recover the unknown PDF from observations. In some cases theory can guide us to a parametric form for the PDF, but more often than not such guidance is not available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "There is a common, simple, and very familiar tool for density estimation: histograms. \n",
    "\n",
    "But there is also a problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "HISTOGRAMS LIE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We will \"prove\" this via example. Using the Linnerud data set, which tested 20 middle aged men by measuring the number of chinups, situps, and jumps they could do in order to compare these numbers to their weight, pulse, and waist size. Execute the cell below to load the data (just chinups for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud = load_linnerud()\n",
    "chinups = linnerud.data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1a** \n",
    "\n",
    "Plot the histogram for the number of chinups using the default settings in pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist( # complete\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('N', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Something is wrong here - the histogram suggests that there is a 0% probability that middle aged men can do 10 chinups. This is intuitively incorrect - what if we adjust the histogram bins?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Problem 1b** \n",
    "\n",
    "Make 2 new histograms: (i) one with 5 bins (`bins = 5`), and (ii) one with the bars centered on the left bin edges (`align = \"left\"`).\n",
    "\n",
    "*Hint - if overplotting the results, you may find it helpful to use the `histtype = \"step\"` option*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(# complete\n",
    "ax.hist(# complete\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('N', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "These small changes significantly change the estimator for the PDF. Fewer bins avoid probability = 0, while shifting the bin centers reduces the probability to zero at 9 chinups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "What if we instead allow the bin width to vary and require the same number of points in each bin? You can determine the bin edges for bins with 5 sources using the following command:\n",
    "\n",
    "`bins = np.append(np.sort(chinups)[::5], \n",
    "                  np.max(chinups))`\n",
    "\n",
    "**Problem 1c** \n",
    "\n",
    "Plot a histogram with variable width bins, each with the same number of points.\n",
    "\n",
    "*Hint - setting `density = True` will normalize the bin heights so that the PDF integrates to 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = np.append(# complete\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist( # complete\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('N', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "*Ending the lie* \n",
    "\n",
    "Histograms lie, tell the \"truth\": show all the data so the effects of bin choices are clear\n",
    ".  Adding a rug plot, which shows a vertical tick for each source, provides additional clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "(If your data set is large, i.e., if you are a survey astronomer in 2025, rug plots are cumbersome and likely to be ineffective...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Problem 1d** \n",
    "\n",
    "Execute the cell below to see an example of a rug plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(chinups, histtype = 'step')\n",
    "\n",
    "# this is the code for the rug plot\n",
    "ax.plot(chinups, np.zeros_like(chinups), '|', color='k', ms = 25, mew = 4)\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('N', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Rug plots are also imperfect. What if a measurement is repeated? A (slightly) better solution is to vary the transparency of the rug \"whiskers\" using `alpha = 0.3`. But this too is far from perfect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "To recap, histograms are not ideal for density estimation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* They introduce discontinuities that are not present in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* They are strongly sensitive to user choices ($N_\\mathrm{bins}$, bin centering, bin grouping), without any mathematical guidance to what these choices should be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* They are difficult to visualize in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Histograms are useful for generating a quick representation of univariate data, but they should never be used for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Never, ever, ever, EVER fit functions to histograms given how greatly the number of bins and bin centering affects the output histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "There must be a better option!\n",
    "\n",
    "(*sound of slowly building classical music*) Enter: [Kernel Density Estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation) (KDE). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "KDE is a nonparametric density estimation method that uses a normalized kernel function convolved with discrete data to estimate the underlying PDF. The kernel must integrate to 1 over the interval $-\\infty$ to $\\infty$ and be symmetric. Popular kernels include Gaussian and Epanechnikov, the latter minimizing mean square error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "KDE is not completely free of the problems above (both a kernel and its width need to be selected), but it does manage to correct a number of the ills. We will now demonstrate this via a few examples using the `scikit-learn` implementation of KDE: [`KernelDensity`](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "*Note* – Jake VanderPlas has put together [an excellent description of different python KDE implementations](https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "To demonstrate the basic idea behind KDE, represent each point in the dataset as a block (i.e., the tophat kernel). We can estimate the KDE using the following code:\n",
    "\n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    def kde_sklearn(data, grid, bandwidth = 1.0, **kwargs):\n",
    "        kde_skl = KernelDensity(bandwidth = bandwidth, **kwargs)\n",
    "        kde_skl.fit(data[:, np.newaxis])\n",
    "        log_pdf = kde_skl.score_samples(grid[:, np.newaxis]) # sklearn returns log(density)\n",
    "        \n",
    "        return np.exp(log_pdf)\n",
    "        \n",
    "The two main options to set are the bandwidth and the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "from sklearn.neighbors import KernelDensity\n",
    "def kde_sklearn(data, grid, bandwidth = 1.0, **kwargs):\n",
    "    kde_skl = KernelDensity(bandwidth = bandwidth, **kwargs)\n",
    "    kde_skl.fit(data[:, np.newaxis])\n",
    "    log_pdf = kde_skl.score_samples(grid[:, np.newaxis]) # sklearn returns log(density)\n",
    "\n",
    "    return np.exp(log_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Problem 1e** \n",
    "\n",
    "Plot the KDE of the PDF for the number of chinups middle aged men can do using a bandwidth of 0.1 and a tophat kernel.\n",
    "\n",
    "*Hint - as a general rule, the grid should be smaller than the bandwidth when plotting the PDF (i.e., >200 points in this case)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid = # complete\n",
    "PDFtophat = kde_sklearn( # complete\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot( # complete\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('PDF', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this representation, each \"block\" has a height of 0.25. The bandwidth is too narrow to provide any overlap between the blocks. This choice of kernel and bandwidth produces an estimate that is essentially a histogram with a large number of bins. It gives no sense of continuity for the distribution. Now, we examine the difference (relative to histograms) upon changing the the width (i.e. kernel) of the blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Problem 1f** \n",
    "\n",
    "Plot the KDE of the PDF for the number of chinups middle aged men can do using bandwidths of 1 and 5 and a tophat kernel. \n",
    "\n",
    "How do the results differ from the histogram plots above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PDFtophat1 = # complete\n",
    "PDFtophat5 = # complete\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(# complete\n",
    "ax.plot(# complete\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('PDF', fontsize=14)\n",
    "fig.tight_layout()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Blocks are not an ideal representation for continuous data. What about a Gaussian?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1g** Plot the KDE of the PDF for the number of chinups middle aged men can do using a gaussian and Epanechnikov kernel. How do the results differ from the histogram plots above? \n",
    "\n",
    "*Hint - you will need to select the bandwidth. The examples above should provide insight into the useful range for bandwidth selection. You may need to adjust the values to get an answer you \"like.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "PDFgaussian = # complete\n",
    "PDFepanechnikov = # complete\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(# complete\n",
    "ax.plot(# complete\n",
    "ax.legend(loc = 2)\n",
    "ax.set_xlabel('chinups', fontsize=14)\n",
    "ax.set_ylabel('PDF', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "So, what is the *optimal* choice of bandwidth and kernel? \n",
    "\n",
    "This varies by problem. Generally, bandwidth is more crucial than the kernel choice. For nearly Gaussian PDFs, Silverman's rule of thumb can be used:\n",
    "\n",
    "$$h = 1.059 \\sigma n^{-1/5}$$\n",
    "\n",
    "where $h$ is the bandwidth, $\\sigma$ is the standard deviation, and $n$ is the sample size. However, this rule may be inaccurate for bimodal or complex distributions. Cross-validation is the most general method for estimating bandwidth, which will be covered in the Machine Learning session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "*What about multidimensional PDFs?* It is possible using many of the Python implementations of KDE to estimate multidimensional PDFs, though it is very very important to beware the curse of dimensionality in these circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 2) Data Exploration\n",
    "\n",
    "**Disclaimer** – there is no single best method for data exploration. \n",
    "\n",
    "As an example we will start with a basic line plot - and examine tools beyond `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 6*np.pi, 0.1)\n",
    "y = np.cos(x)\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "ax.plot(x,y, lw = 2)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_xlim(0, 6*np.pi)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Seaborn\n",
    "\n",
    "[`Seaborn`](https://stanford.edu/~mwaskom/software/seaborn/index.html) is a plotting package that enables many useful features for exploration. \n",
    "\n",
    "Built-in tools in `seaborn` can reproduce everything from **Problem 1** in a single call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Recreate the above `matplotlib` plot using `Seaborn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x,y, lw = 2)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_xlim(0, 6*np.pi)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "These plots look identical, but it is possible to change the style with `seaborn`. \n",
    "\n",
    "`seaborn` has 5 style presets: `darkgrid`, `whitegrid`, `dark`, `white`, and `ticks`. You can change the preset using the following: \n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    " \n",
    "which will change the output for all subsequent plots. Note - if you want to change the style for only a single plot, that can be accomplished with the following: \n",
    "\n",
    "    with sns.axes_style(\"dark\"):\n",
    "\n",
    "with all ploting commands inside the `with` statement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 2a** \n",
    "\n",
    "Re-plot the sine curve using each `seaborn` preset to see which you like best - then adopt this for the remainder of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(# complete\n",
    "\n",
    "# complete\n",
    "# complete\n",
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `seaborn` devs have thought a lot about color palettes.\n",
    "\n",
    "A poor choice of colors can easily mask interesting patterns or suggest structure that is not real. To learn more about what is available, see the [`seaborn` color tutorial](http://stanford.edu/~mwaskom/software/seaborn/tutorial/color_palettes.html). \n",
    "\n",
    "Here we load the default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# default color palette\n",
    "\n",
    "current_palette = sns.color_palette()\n",
    "sns.palplot(current_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "which we will now change to `colorblind`, which is clearer to those that are colorblind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set palette to colorblind\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "current_palette = sns.color_palette()\n",
    "sns.palplot(current_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Beyond the basics (we barely scratched the surface), `seaborn` is also powerful for higher dimension data sets. \n",
    "\n",
    "Consider the famous Iris data set, which measures 4 different features of 3 different types of 150 Iris flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "*Note - for those familiar with `pandas` `seaborn` is designed to integrate easily and directly with `pandas DataFrame` objects. In the example below the Iris data are loaded into a `DataFrame`. `jupyter` notebooks also display the `DataFrame` data in a nice readable format.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We went to great pains to produce histograms, KDEs, and rug plots in **Problem 1**. `seaborn` handles all of that effortlessly with the [`displot`](https://seaborn.pydata.org/generated/seaborn.displot.html) function.\n",
    "\n",
    "**Problem 2b** \n",
    "\n",
    "Plot the distribution of petal lengths for the Iris data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# note - kde, and rug all set to True, set to False to turn them off \n",
    "with sns.axes_style(\"dark\"):\n",
    "    sns.displot(iris['petal_length'], bins=20, \n",
    "                kde=True, rug=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Iris data lives in a 4D space, so plotting more than univariate distributions is important. Fortunately, `seaborn` makes it easy to produce handy summary plots (in a way that is far more comprehensive than `matplotlib`). \n",
    "\n",
    "**Problem 2c** \n",
    "\n",
    "Make a matplotlib scatter plot showing the Iris petal length against the Iris petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter( # complete\n",
    "ax.set_xlabel(\"petal length (cm)\")\n",
    "ax.set_ylabel(\"petal width (cm)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Aside**\n",
    "\n",
    "When there are many many data points, scatter plots become difficult to interpret. \n",
    "\n",
    "Execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2016)\n",
    "xexample = np.random.normal(loc = 0.2, scale = 1.1, size = 10000)\n",
    "yexample = np.random.normal(loc = -0.2, scale = 0.9, size = 10000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xexample, yexample)\n",
    "ax.set_xlabel('X', fontsize=14)\n",
    "ax.set_ylabel('Y', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, we see that there are many points, clustered about the origin, but we have no sense of the underlying density of the distribution. 2D histograms, such as `plt.hist2d()`, can alleviate this problem. I prefer to use `plt.hexbin()` which is a little easier on the eyes (though note - these histograms are just as subject to the same issues discussed above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# hexbin w/ bins = \"log\" returns the log of counts/bin\n",
    "# mincnt = 1 displays only hexpix with at least 1 source present\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.hexbin(xexample, yexample, bins = \"log\", cmap = \"viridis\", mincnt = 1)\n",
    "ax.set_xlabel('X', fontsize=14)\n",
    "ax.set_ylabel('Y', fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While the above plot provides a significant improvement over the scatter plot by providing a better sense of the density near the center of the distribution, the binedge effects are clearly present. Similar to **1g** a density estimate is superior. KDEs are easy in `seaborn` via the `kdeplot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(x=xexample, y=yexample, shade=False)\n",
    "ax.set_xlabel('X', fontsize=14)\n",
    "ax.set_ylabel('Y', fontsize=14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This plot is much more appealing (and informative) than the previous two. For the first time we can clearly see that the distribution is not actually centered on the origin. Now we will move back to the Iris data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we want to see univariate distributions in addition to the scatter plot? This is certainly possible with `matplotlib` and you can find examples on the web, however, with `seaborn` this is really easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=iris['petal_length'], y=iris['petal_width'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But! Histograms and scatter plots can be problematic as we have discussed many times before. \n",
    "\n",
    "**Problem 2d** \n",
    "\n",
    "Re-create the plot above but set `kind='kde'` to produce density estimates of the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(# complete\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That is much nicer than what was presented above. However - we still have a problem in that our data live in 4D, but we are (mostly) limited to 2D projections of that data. One way around this is via the `seaborn` version of a `pairplot`, which plots the distribution of every variable in the data set against each other. (Here is where the integration with `pandas DataFrame`s becomes so powerful.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(iris[[\"sepal_length\", \"sepal_width\", \n",
    "                   \"petal_length\", \"petal_width\"]])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For data sets where we have classification labels, we can even color the various points using the `hue` option, and produce KDEs along the diagonal with `diag_type = 'kde'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(iris, vars = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "             hue = \"species\", diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Even better - there is an option to create a `PairGrid` which allows fine tuned control of the data as displayed above, below, and along the diagonal. In this way it becomes possible to avoid having symmetric redundancy, which is not all that informative. In the example below, we will show scatter plots and contour plots simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(iris, vars = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "                 hue = \"species\", diag_sharey=False)\n",
    "g.map_lower(sns.kdeplot)\n",
    "g.map_upper(plt.scatter, edgecolor='white')\n",
    "g.map_diag(sns.kdeplot, lw=3)\n",
    "g.add_legend()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "haniyeh_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "solarized"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
